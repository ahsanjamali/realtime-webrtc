// Set the basic API address for communication with the backend server
const baseUrl = "http://localhost:8813";
// Flag indicating whether WebRTC is active, controls the enabling and disabling of connections
let isWebRTCActive = false;
// Create variables related to the WebRTC connection
let peerConnection;
let dataChannel;
// Define an object that contains multiple functions; methods in fns will be called
const fns = {
  // Add the search function
  search_hospital: async ({ query }) => {
    try {
      const response = await fetch(`${baseUrl}/api/search`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ query }),
      });

      const data = await response.json();
      return {
        success: true,
        results: data.results,
      };
    } catch (error) {
      return {
        success: false,
        error: error.message,
      };
    }
  },
};

// When an audio stream is received, add it to the page and play it
function handleTrack(event) {
  const el = document.createElement("audio"); // Create an audio element
  el.srcObject = event.streams[0]; // Set the audio stream as the element's source
  el.autoplay = el.controls = true; // Autoplay and display audio controls
  document.body.appendChild(el); // Add the audio element to the page
}

// Create a data channel for transmitting control messages (such as function calls)
function createDataChannel() {
  // Create a data channel named 'response'
  dataChannel = peerConnection.createDataChannel("response");

  // Configure data channel events
  dataChannel.addEventListener("open", () => {
    console.log("Data channel opened");
    configureData(); // Configure data channel functions
  });

  // Move the message event listener here inside createDataChannel
  dataChannel.addEventListener("message", async (ev) => {
    const msg = JSON.parse(ev.data);
    console.log("Received message type:", msg.type, "Full message:", msg);

    // Handle function calls
    if (msg.type === "response.function_call_arguments.done") {
      const fn = fns[msg.name];
      if (fn !== undefined) {
        console.log(
          `Calling local function ${msg.name}, parameters ${msg.arguments}`
        );
        const args = JSON.parse(msg.arguments);
        const result = await fn(args);
        console.log("Result", result);
        const event = {
          type: "conversation.item.create",
          item: {
            type: "function_call_output",
            call_id: msg.call_id,
            output: JSON.stringify(result),
          },
        };
        dataChannel.send(JSON.stringify(event));
      }
    }

    // Handle text responses
    if (msg.type === "response.text.delta") {
      console.log("Received text delta:", msg.delta);
      addMessageToChat(msg.delta, false);
    }

    // Handle final response output
    if (msg.type === "response.done") {
      console.log("Final response:", msg.response.output[0]);
      // Check if there's content in the output
      const output = msg.response.output[0];
      const outputContent = msg.response.output[0];
      console.log("Output content:", outputContent);
      if (output && output.content) {
        for (const content of output.content) {
          if (content.type === "text") {
            addMessageToChat(content.text, false);
          } else if (content.type === "audio" && content.transcript) {
            addMessageToChat(content.transcript, false);
          }
        }
      }
    }
  });
}

// Configure data channel functions and tools
function configureData() {
  console.log("Configuring data channel");
  const event = {
    type: "session.update", // Session update event
    session: {
      instructions:
        "You are a Patient Virtual Assistant for Doctor Samir Abbas Hospital in Jeddah. In the tools you have the search tool to search through the knowledge base of hospital to find relevant information. Respond to the user in a friendly and helpful manner.",
      modalities: ["audio", "text"], // Supported interaction modes: text and audio
      // Provide functional tools, pay attention to the names of these tools corresponding to the keys in the above fns object
      tools: [
        // Add the search tool definition
        {
          type: "function",
          name: "search_hospital",
          description:
            "Search through the knowledge base of hospital to find relevant information",
          parameters: {
            type: "object",
            properties: {
              query: {
                type: "string",
                description: "The search query to find relevant information",
              },
            },
            required: ["query"],
          },
        },
      ],
    },
  };
  dataChannel.send(JSON.stringify(event)); // Send the configured event data
}

// Get the control button element
const toggleButton = document.getElementById("toggleWebRTCButton");
// Add a click event listener to the button to toggle the WebRTC connection state
toggleButton.addEventListener("click", () => {
  // If WebRTC is active, stop the connection; otherwise, start WebRTC
  if (isWebRTCActive) {
    stopWebRTC(); // Stop WebRTC
    toggleButton.textContent = "start"; // Update button text
  } else {
    startWebRTC(); // Start WebRTC
    toggleButton.textContent = "stop"; // Update button text
  }
});

// Capture microphone input stream and initiate WebRTC connection
function startWebRTC() {
  // If WebRTC is already active, return directly
  if (isWebRTCActive) return;
  // Create a new peerConnection object to establish a WebRTC connection
  peerConnection = new RTCPeerConnection();
  peerConnection.ontrack = handleTrack; // Bind audio stream processing function
  createDataChannel(); // Create data channel
  // Request user's audio stream
  navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
    // Add each track from the audio stream to the peerConnection
    stream
      .getTracks()
      .forEach((track) =>
        peerConnection.addTransceiver(track, { direction: "sendrecv" })
      );
    // Create an offer for the local connection
    peerConnection.createOffer().then((offer) => {
      peerConnection.setLocalDescription(offer); // Set local description (offer)
      // Send the offer to the backend for signaling exchange
      fetch(baseUrl + "/api/rtc-connect", {
        method: "POST",
        body: offer.sdp, // Send the SDP of the offer to the backend
        headers: {
          "Content-Type": "application/sdp",
        },
      })
        .then((r) => r.text())
        .then((answer) => {
          // Get the answer returned by the backend and set it as the remote description
          peerConnection.setRemoteDescription({ sdp: answer, type: "answer" });
        });
    });
  });
  // Mark WebRTC as active
  isWebRTCActive = true;
}

// Stop the WebRTC connection and clean up all resources
function stopWebRTC() {
  // If WebRTC is not active, return directly
  if (!isWebRTCActive) return;
  // Stop the received audio tracks
  const tracks = peerConnection
    .getReceivers()
    .map((receiver) => receiver.track);
  tracks.forEach((track) => track.stop());
  // Close the data channel and WebRTC connection
  if (dataChannel) dataChannel.close();
  if (peerConnection) peerConnection.close();
  // Reset connection and channel objects
  peerConnection = null;
  dataChannel = null;
  // Mark WebRTC as not active
  isWebRTCActive = false;
}

// Add these new functions and event listeners after the existing code
const textInput = document.getElementById("textInput");
const sendButton = document.getElementById("sendButton");
const chatMessages = document.getElementById("chatMessages");

// Function to add a message to the chat display
function addMessageToChat(text, isUser = false) {
  const messageDiv = document.createElement("div");
  messageDiv.className = `message ${
    isUser ? "user-message" : "assistant-message"
  }`;
  messageDiv.textContent = text;
  chatMessages.appendChild(messageDiv);
  chatMessages.scrollTop = chatMessages.scrollHeight;
}

// Function to send text message to the model
async function sendTextMessage(text) {
  if (!isWebRTCActive || !dataChannel) {
    console.log("WebRTC status:", isWebRTCActive, "dataChannel:", dataChannel);
    alert("Please start the connection first");
    return;
  }

  console.log("Sending message:", text);
  // Add user message to chat
  addMessageToChat(text, true);

  // Create conversation item with text
  const createMessage = {
    type: "conversation.item.create",
    item: {
      type: "message",
      role: "user",
      content: [
        {
          type: "input_text",
          text: text,
        },
      ],
    },
  };

  // Send the message
  dataChannel.send(JSON.stringify(createMessage));

  // Request response from the model
  const createResponse = {
    type: "response.create",
    response: {
      modalities: ["text", "audio"],
    },
  };

  dataChannel.send(JSON.stringify(createResponse));
}

// Handle send button click
sendButton.addEventListener("click", () => {
  const text = textInput.value.trim();
  if (text) {
    sendTextMessage(text);
    textInput.value = "";
  }
});

// Handle enter key in input
textInput.addEventListener("keypress", (e) => {
  if (e.key === "Enter") {
    const text = textInput.value.trim();
    if (text) {
      sendTextMessage(text);
      textInput.value = "";
    }
  }
});
